{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035d9b23-f990-4d48-aed8-c6f0353e5e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N.rows: 3419\n",
      "N.col: 12\n",
      "Displaying 10 rows:\n",
      "+---------+------------------+------------------+------------------+-----------------+------------------+------------------+-------------------+\n",
      "|device_id|          avg_temp|      avg_humidity|      avg_pressure|  avg_air_quality|   avg_noise_level| avg_battery_level|avg_signal_strength|\n",
      "+---------+------------------+------------------+------------------+-----------------+------------------+------------------+-------------------+\n",
      "| sensor_1|27.580568011958153| 55.14648729446936|1014.2739520958083|51.64221556886228| 56.81437125748503| 54.15119760479042| -60.17365269461078|\n",
      "| sensor_4|27.618080808080816| 55.86147186147186|1013.6994219653179|50.02167630057804|56.372832369942195| 53.74710982658959| -59.40462427745665|\n",
      "| sensor_2|27.533811659192825| 53.69506726457399|1015.7563527653214|51.34977578475336|54.478325859491775|53.926756352765324|-60.663677130044846|\n",
      "| sensor_3|27.470942562592032|54.166421207658324|1014.7085798816568|51.73224852071006| 55.28550295857988| 54.34171597633136|-58.744082840236686|\n",
      "| sensor_5|27.602633136094713|54.917159763313606|1014.8565088757397|51.32248520710059| 54.63165680473373|55.875739644970416|  -60.2292899408284|\n",
      "+---------+------------------+------------------+------------------+-----------------+------------------+------------------+-------------------+\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "from pyspark.sql.functions import col, when, avg, to_timestamp\n",
    "import os\n",
    "\n",
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"IoT ETL Pipeline\") \\\n",
    "        .config(\"spark.driver.extraClassPath\", \"/home/jovyan/work/Graduation/mssql-jdbc-13.2.1.jre8.jar\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"timestamp\", StringType(), True),\n",
    "    StructField(\"device_id\", StringType(), True),\n",
    "    StructField(\"temperature\", DoubleType(), True),\n",
    "    StructField(\"humidity\", IntegerType(), True),\n",
    "    StructField(\"pressure\", IntegerType(), True),\n",
    "    StructField(\"air_quality\", IntegerType(), True),\n",
    "    StructField(\"noise_level\", IntegerType(), True),\n",
    "    StructField(\"battery_level\", IntegerType(), True),\n",
    "    StructField(\"signal_strength\", IntegerType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True),\n",
    "    StructField(\"raw_message\", StringType(), True)\n",
    "])\n",
    "\n",
    "data_folder = \"/home/jovyan/work/Graduation/_IOT_Batches\"\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").schema(schema).csv(os.path.join(data_folder, \"*.csv\"))\n",
    "\n",
    "print(\"N.rows:\", df.count())\n",
    "print(\"N.col:\", len(df.columns))\n",
    "\n",
    "df = df.withColumn(\"timestamp\", to_timestamp(\"timestamp\", \"yyyy-MM-dd'T'HH:mm:ss.SSSSSS\"))\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"temperature_status\",\n",
    "    when(col(\"temperature\") > 30, \"High\")\n",
    "    .when(col(\"temperature\") < 22, \"Low\")\n",
    "    .otherwise(\"Normal\")\n",
    ")\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"battery_status\",\n",
    "    when(col(\"battery_level\") < 20, \"Low Battery\")\n",
    "    .otherwise(\"OK\")\n",
    ")\n",
    "\n",
    "if \"temperature\" in df.columns:\n",
    "    df = df.filter((col(\"temperature\") >= -10) & (col(\"temperature\") <= 60))\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"anomaly_flag\",\n",
    "    when((col(\"temperature\") > 40) | (col(\"temperature\") < 10), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "agg_df = df.groupBy(\"device_id\").agg(\n",
    "    avg(\"temperature\").alias(\"avg_temp\"),\n",
    "    avg(\"humidity\").alias(\"avg_humidity\"),\n",
    "    avg(\"pressure\").alias(\"avg_pressure\"),\n",
    "    avg(\"air_quality\").alias(\"avg_air_quality\"),\n",
    "    avg(\"noise_level\").alias(\"avg_noise_level\"),\n",
    "    avg(\"battery_level\").alias(\"avg_battery_level\"),\n",
    "    avg(\"signal_strength\").alias(\"avg_signal_strength\")\n",
    ")\n",
    "\n",
    "print(\"Displaying 10 rows:\")\n",
    "agg_df.show(10)\n",
    "\n",
    "jdbc_url = \"jdbc:sqlserver://host.docker.internal:1433;databaseName=IoT_DB;encrypt=false;\"\n",
    "\n",
    "connection_properties = {\n",
    "    \"user\": \"sa\",\n",
    "    \"password\": \"Salma_SQL@2005DEPI\",\n",
    "    \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "}\n",
    "\n",
    "df.write.jdbc(url=jdbc_url, table=\"iot_data\", mode=\"overwrite\", properties=connection_properties)\n",
    "agg_df.write.jdbc(url=jdbc_url, table=\"iot_summary\", mode=\"overwrite\", properties=connection_properties)\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
